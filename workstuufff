import pandas as pd
import numpy as np
import os

def exact_match_weighting_complete(accts, df_all, exposure_col='os_bal_cad_amt'):
    """
    Complete exact match weighting process
    - No pd_seg dimension
    - No fallback hierarchy 
    - Zero weights for unmatched segments
    """
    
    print("="*80)
    print("EXACT MATCH WEIGHTING - COMPLETE PROCESS")
    print("="*80)
    print(f"Input shapes: accts={accts.shape}, df_all={df_all.shape}")
    print(f"Exposure column: {exposure_col}")
    
    # =========================================================================
    # STEP 1: ANALYZE DATA COVERAGE
    # =========================================================================
    print("\n" + "="*50)
    print("STEP 1: ANALYZING DATA COVERAGE")
    print("="*50)
    
    # Get unique segment combinations (without pd_seg)
    accts_segments = accts[['cntry_cd', 'bus_entity', 'prd_cd', 'bhvr_score_aligned']].drop_duplicates()
    df_all_segments = df_all[['cntry_cd', 'bus_entity', 'prd_cd', 'bhvr_score_aligned']].drop_duplicates()
    
    print(f"Unique segments - accts: {len(accts_segments)}, df_all: {len(df_all_segments)}")
    
    # Find which df_all segments exist in accts
    merged_check = df_all_segments.merge(
        accts_segments, 
        on=['cntry_cd', 'bus_entity', 'prd_cd', 'bhvr_score_aligned'],
        how='left',
        indicator=True
    )
    
    matched_count = (merged_check['_merge'] == 'both').sum()
    unmatched_count = (merged_check['_merge'] == 'left_only').sum()
    
    print(f"Segments that will get weights: {matched_count}")
    print(f"Segments that will get zero weight: {unmatched_count}")
    print(f"Coverage rate: {matched_count/(matched_count+unmatched_count)*100:.1f}%")
    
    # =========================================================================
    # STEP 2: CALCULATE SEGMENT WEIGHTS (EXACT MATCHES ONLY)
    # =========================================================================
    print("\n" + "="*50)
    print("STEP 2: CALCULATING SEGMENT WEIGHTS")
    print("="*50)
    
    # Group account data by segments to get exposure per segment
    segment_weights = accts.groupby(['cntry_cd', 'prd_cd', 'bus_entity', 'bhvr_score_aligned']).agg({
        exposure_col: 'sum',
        'acct_num': 'count'
    }).reset_index()
    segment_weights = segment_weights.rename(columns={
        exposure_col: 'segment_exposure', 
        'acct_num': 'account_count'
    })
    
    print(f"Segments with calculated weights: {len(segment_weights)}")
    print(f"Total exposure across all segments: ${segment_weights['segment_exposure'].sum():,.0f}")
    
    # Calculate total exposure by country-product for normalization
    cp_totals = segment_weights.groupby(['cntry_cd', 'prd_cd'])['segment_exposure'].sum().reset_index()
    cp_totals = cp_totals.rename(columns={'segment_exposure': 'cp_total_exposure'})
    
    print(f"Country-product combinations in account data: {len(cp_totals)}")
    
    # Merge totals back and calculate weights
    segment_weights = segment_weights.merge(cp_totals, on=['cntry_cd', 'prd_cd'])
    segment_weights['weight'] = segment_weights['segment_exposure'] / segment_weights['cp_total_exposure']
    
    # Validate weights sum to 1 within each country-product
    weight_check = segment_weights.groupby(['cntry_cd', 'prd_cd'])['weight'].sum()
    print(f"Weight validation - Min: {weight_check.min():.6f}, Max: {weight_check.max():.6f}, Mean: {weight_check.mean():.6f}")
    
    if not np.allclose(weight_check, 1.0, rtol=1e-10):
        print("⚠️  WARNING: Weights don't sum to 1.0 within country-product groups!")
    else:
        print("✅ Weight validation passed - all sum to 1.0")
    
    # Show sample weights
    print("\nSample segment weights:")
    print(segment_weights[['cntry_cd', 'prd_cd', 'bus_entity', 'bhvr_score_aligned', 'weight', 'segment_exposure']].head())
    
    # =========================================================================
    # STEP 3: APPLY WEIGHTS TO DF_ALL
    # =========================================================================
    print("\n" + "="*50)
    print("STEP 3: APPLYING WEIGHTS TO DETAILED DATA")
    print("="*50)
    
    # Merge df_all with calculated weights
    df_weighted = df_all.merge(
        segment_weights[['cntry_cd', 'prd_cd', 'bus_entity', 'bhvr_score_aligned', 'weight', 'segment_exposure', 'account_count']], 
        on=['cntry_cd', 'prd_cd', 'bus_entity', 'bhvr_score_aligned'], 
        how='left'
    )
    
    # Count matches vs non-matches
    matched_records = df_weighted['weight'].notna().sum()
    unmatched_records = df_weighted['weight'].isna().sum()
    
    print(f"Records that matched account data: {matched_records:,}")
    print(f"Records that will get zero weight: {unmatched_records:,}")
    print(f"Match rate: {matched_records/(matched_records+unmatched_records)*100:.1f}%")
    
    # Assign zero weight to unmatched segments
    df_weighted['weight'] = df_weighted['weight'].fillna(0)
    df_weighted['segment_exposure'] = df_weighted['segment_exposure'].fillna(0)
    df_weighted['account_count'] = df_weighted['account_count'].fillna(0)
    
    # Add indicator for weight source
    df_weighted['has_account_weight'] = df_weighted['weight'] > 0
    
    # Calculate weighted fli_perf for each record
    df_weighted['weighted_fli_perf'] = df_weighted['fli_perf'] * df_weighted['weight']
    
    print("✅ Weights applied successfully")
    
    # =========================================================================
    # STEP 4: AGGREGATE TO COUNTRY-PRODUCT-DATE LEVEL
    # =========================================================================
    print("\n" + "="*50)
    print("STEP 4: AGGREGATING TO COUNTRY-PRODUCT-DATE LEVEL")
    print("="*50)
    
    # Aggregate by country, product, date
    final_result = df_weighted.groupby(['cntry_cd', 'prd_cd', 'cal_dt']).agg({
        'weighted_fli_perf': 'sum',           # Sum of weighted performance
        'fli_perf': ['mean', 'count', 'std'], # Original stats for comparison
        'weight': 'sum',                      # Total weight coverage
        'segment_exposure': 'sum',            # Total exposure
        'account_count': 'sum',               # Total accounts
        'has_account_weight': 'sum',          # Number of records with weights
        'pd': 'mean',                         # Average PD
        'lgd': 'mean'                         # Average LGD
    }).reset_index()
    
    # Flatten column names
    final_result.columns = [
        'cntry_cd', 'prd_cd', 'cal_dt',
        'weighted_fli_perf_sum',
        'fli_perf_simple_mean', 'total_records', 'fli_perf_std',
        'weight_coverage', 'total_exposure', 'total_accounts', 'records_with_weights',
        'avg_pd', 'avg_lgd'
    ]
    
    # Calculate final normalized weighted fli_perf
    final_result['weighted_fli_perf'] = np.where(
        final_result['weight_coverage'] > 0,
        final_result['weighted_fli_perf_sum'] / final_result['weight_coverage'],
        final_result['fli_perf_simple_mean']  # Fallback to simple average if no account weights
    )
    
    # Calculate coverage metrics
    final_result['weight_coverage_pct'] = final_result['weight_coverage'] * 100
    final_result['records_with_weights_pct'] = (final_result['records_with_weights'] / final_result['total_records']) * 100
    
    print(f"Final result shape: {final_result.shape}")
    print(f"Date range: {final_result['cal_dt'].min()} to {final_result['cal_dt'].max()}")
    print(f"Countries: {final_result['cntry_cd'].nunique()}")
    print(f"Products: {final_result['prd_cd'].nunique()}")
    
    # =========================================================================
    # STEP 5: VALIDATION AND SUMMARY STATISTICS
    # =========================================================================
    print("\n" + "="*50)
    print("STEP 5: VALIDATION AND SUMMARY")
    print("="*50)
    
    # Weight coverage analysis
    print("Weight Coverage Distribution:")
    coverage_bins = [0, 0.25, 0.5, 0.75, 0.95, 1.0]
    coverage_labels = ['0%', '1-25%', '26-50%', '51-75%', '76-95%', '96-100%']
    final_result['coverage_bin'] = pd.cut(final_result['weight_coverage'], 
                                        bins=coverage_bins, 
                                        labels=coverage_labels, 
                                        include_lowest=True)
    coverage_dist = final_result['coverage_bin'].value_counts().sort_index()
    print(coverage_dist)
    
    # Summary by country
    print("\nSummary by Country:")
    country_summary = final_result.groupby('cntry_cd').agg({
        'weighted_fli_perf': 'mean',
        'weight_coverage': 'mean',
        'total_exposure': 'sum',
        'total_records': 'sum'
    }).round(6)
    print(country_summary)
    
    # Summary by product
    print("\nSummary by Product:")
    product_summary = final_result.groupby('prd_cd').agg({
        'weighted_fli_perf': 'mean',
        'weight_coverage': 'mean', 
        'total_exposure': 'sum',
        'total_records': 'sum'
    }).round(6)
    print(product_summary)
    
    # Compare weighted vs simple average
    print(f"\nWeighted vs Simple Average Comparison:")
    final_result['difference'] = final_result['weighted_fli_perf'] - final_result['fli_perf_simple_mean']
    final_result['pct_difference'] = np.where(
        final_result['fli_perf_simple_mean'] != 0,
        (final_result['difference'] / final_result['fli_perf_simple_mean']) * 100,
        0
    )
    
    print(f"Mean absolute difference: {final_result['difference'].abs().mean():.6f}")
    print(f"Mean absolute % difference: {final_result['pct_difference'].abs().mean():.2f}%")
    print(f"Max absolute % difference: {final_result['pct_difference'].abs().max():.2f}%")
    
    # Show sample final results
    print(f"\nSample Final Results:")
    sample_cols = ['cntry_cd', 'prd_cd', 'cal_dt', 'weighted_fli_perf', 
                   'fli_perf_simple_mean', 'weight_coverage_pct', 'total_exposure']
    print(final_result[sample_cols].head(10))
    
    print("\n" + "="*80)
    print("✅ EXACT MATCH WEIGHTING COMPLETE!")
    print("="*80)
    print(f"🎯 Your weighted FLI performance is in column: 'weighted_fli_perf'")
    print(f"📊 Weight coverage information is in: 'weight_coverage_pct'")
    print(f"💰 Exposure totals are in: 'total_exposure'")
    print(f"📈 Simple average comparison is in: 'fli_perf_simple_mean'")
    
    return final_result, df_weighted, segment_weights

def export_results(final_result, df_weighted, segment_weights, output_dir="./output/"):
    """
    Export all results to CSV files
    """
    print(f"\n" + "="*50)
    print("EXPORTING RESULTS")
    print("="*50)
    
    # Create output directory if it doesn't exist
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        print(f"Created directory: {output_dir}")
    
    try:
        # Export final aggregated results
        final_result.to_csv(f"{output_dir}/weighted_fli_performance_final.csv", index=False)
        print(f"✅ Exported final results: {output_dir}/weighted_fli_performance_final.csv")
        
        # Export segment weights
        segment_weights.to_csv(f"{output_dir}/segment_weights.csv", index=False)
        print(f"✅ Exported segment weights: {output_dir}/segment_weights.csv")
        
        # Export detailed weighted data (if not too large)
        if len(df_weighted) < 1000000:  # Only if less than 1M records
            df_weighted.to_csv(f"{output_dir}/detailed_weighted_data.csv", index=False)
            print(f"✅ Exported detailed data: {output_dir}/detailed_weighted_data.csv")
        else:
            print(f"⚠️  Detailed data too large ({len(df_weighted):,} records) - skipped export")
            
        # Export summary report
        create_summary_report(final_result, segment_weights, f"{output_dir}/summary_report.txt")
        print(f"✅ Exported summary report: {output_dir}/summary_report.txt")
        
    except Exception as e:
        print(f"❌ Export error: {str(e)}")

def create_summary_report(final_result, segment_weights, filename):
    """
    Create a text summary report
    """
    with open(filename, 'w') as f:
        f.write("EXACT MATCH WEIGHTING - SUMMARY REPORT\n")
        f.write("=" * 50 + "\n\n")
        
        f.write(f"Final Dataset Shape: {final_result.shape}\n")
        f.write(f"Date Range: {final_result['cal_dt'].min()} to {final_result['cal_dt'].max()}\n")
        f.write(f"Countries: {', '.join(final_result['cntry_cd'].unique())}\n")
        f.write(f"Products: {', '.join(final_result['prd_cd'].unique())}\n\n")
        
        f.write("Weight Coverage Summary:\n")
        f.write(f"- Full coverage (95-100%): {(final_result['weight_coverage'] >= 0.95).sum()} records\n")
        f.write(f"- Partial coverage (1-94%): {((final_result['weight_coverage'] > 0) & (final_result['weight_coverage'] < 0.95)).sum()} records\n")
        f.write(f"- No coverage (0%): {(final_result['weight_coverage'] == 0).sum()} records\n\n")
        
        f.write(f"Average weighted FLI performance: {final_result['weighted_fli_perf'].mean():.6f}\n")
        f.write(f"Total exposure across all segments: ${final_result['total_exposure'].sum():,.0f}\n")
        f.write(f"Total accounts: {final_result['total_accounts'].sum():,.0f}\n")

# MAIN EXECUTION FUNCTION
def run_complete_exact_match_weighting(accts, df_all, exposure_col='os_bal_cad_amt', export=True, output_dir="./output/"):
    """
    Main function to run the complete exact match weighting process
    
    Parameters:
    - accts: Account-level DataFrame
    - df_all: Detailed FLI performance DataFrame
    - exposure_col: Column name for exposure/balance weighting (default: 'os_bal_cad_amt')
    - export: Whether to export results to CSV (default: True)
    - output_dir: Directory for exported files (default: './output/')
    
    Returns:
    - final_result: Aggregated weighted FLI performance at country-product-date level
    - df_weighted: Detailed data with weights applied
    - segment_weights: Calculated segment weights
    """
    
    print("STARTING COMPLETE EXACT MATCH WEIGHTING PROCESS")
    print("=" * 80)
    
    # Run the complete weighting process
    final_result, df_weighted, segment_weights = exact_match_weighting_complete(
        accts, df_all, exposure_col
    )
    
    # Export results if requested
    if export:
        export_results(final_result, df_weighted, segment_weights, output_dir)
    
    print(f"\n🎉 PROCESS COMPLETED SUCCESSFULLY!")
    print(f"Your weighted FLI performance data is ready in: final_result['weighted_fli_perf']")
    
    return final_result, df_weighted, segment_weights

# USAGE EXAMPLE:
"""
# Run the complete process
final_result, df_weighted, segment_weights = run_complete_exact_match_weighting(
    accts=accts, 
    df_all=df_all,
    exposure_col='os_bal_cad_amt',  # or whatever your exposure column is named
    export=True,
    output_dir="./my_results/"
)

# Your final weighted FLI performance is now available at country-product-date level
# Key columns in final_result:
# - 'weighted_fli_perf': Your main result (exposure-weighted FLI performance)  
# - 'weight_coverage_pct': Shows what % of the segment had account weights
# - 'total_exposure': Total exposure amount for that country-product-date
# - 'fli_perf_simple_mean': Simple average for comparison
"""
